{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/bin/python\n",
      "\n",
      "# Initialize dataset\n",
      "import sys, ply, h5py, pandas as pd, numpy as np\n",
      "sys.path.insert(0,'/scr/litauen1/toro/dist_meta/neurovault/neuro2/neurosynth')\n",
      "from neurosynth.base.dataset import Dataset\n",
      "from neurosynth.analysis import decode\n",
      "from sklearn.cluster import KMeans \n",
      "\n",
      "%matplotlib inline\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "import pylab as plt\n",
      "import scipy.cluster.hierarchy as hier\n",
      "import scipy.spatial.distance as dist\n",
      "sns.set(context=\"paper\", font=\"sans-serif\", font_scale=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the Dataset and add topic-based features--point to right location\n",
      "# in your local environment.\n",
      "\n",
      "#dataset = Dataset('/scr/litauen1/toro/dist_meta/neurovault/neuro2/neurosynth-data/database.txt')\n",
      "#dataset.add_features('/scr/litauen1/toro/dist_meta/neurovault/neuro2/neurosynth-data/features.txt')\n",
      "#dataset.save('/scr/litauen1/toro/dist_meta/neurovault/neuro2/neurosynth-data/dataset.pkl', keep_mappables = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "pickled_dataset = '/scr/litauen1/toro/dist_meta/neurovault/neuro2/neurosynth-data/dataset.pkl'\n",
      "dataset = Dataset.load(pickled_dataset)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "('_reconstruct: First argument must be a sub-type of ndarray', <built-in function _reconstruct>, (<class 'pandas.core.index.Index'>, (0,), 'b'))",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-5-4bafe9d1412e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpickled_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/scr/litauen1/toro/dist_meta/neurovault/neuro2/neurosynth-data/dataset.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickled_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/scr/litauen1/toro/dist_meta/neurovault/neuro2/neurosynth/neurosynth/base/dataset.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, filename)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;34m\"\"\" Load a pickled Dataset instance from file. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'feature_table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_csr_to_sdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: ('_reconstruct: First argument must be a sub-type of ndarray', <built-in function _reconstruct>, (<class 'pandas.core.index.Index'>, (0,), 'b'))"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "'''\n",
      "# Print terms from each topic\n",
      "features = pd.read_csv('v3-topics-50-keys.txt', sep=' |\\t', index_col=0, header=None)\n",
      "features = features.T[topics_to_keep]\n",
      "features.columns = labels\n",
      "print features.T\n",
      "'''\n",
      "''', save='decoding_results.txt')\n",
      "                    \n",
      "# Write out results\n",
      "import csv\n",
      "lola = np.asarray(list(csv.reader(open('decoding_results.txt', 'rb'), delimiter=',')))\n",
      "\n",
      "inputAll = []\n",
      "inputNorm = []\n",
      "namesAll = []\n",
      "names = lola[1:,0]\n",
      "size = np.shape(lola)\n",
      "for i in xrange(1,size[1]):\n",
      "    input = lola[1:,i]\n",
      "    ord = np.argsort(input)\n",
      "    inputAll.append(input[ord][:])\n",
      "    namesAll.append(names[ord][:])\n",
      "    inputNorm.append(input)\n",
      "\n",
      "# Save files for matlab\n",
      "f = h5py.File('neurosynth_meta.mat','w')\n",
      "f['inputAll'] = np.asarray(inputAll)\n",
      "f['namesAll'] = namesAll\n",
      "f['names'] = names\n",
      "f['inputNorm'] = inputNorm\n",
      "f.close()\n",
      "'''\n",
      "#df = pd.read_table('decoding_results.txt', sep=',', header=0, index_col=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 246,
       "text": [
        "\", save='decoding_results.txt')\\n                    \\n# Write out results\\nimport csv\\nlola = np.asarray(list(csv.reader(open('decoding_results.txt', 'rb'), delimiter=',')))\\n\\ninputAll = []\\ninputNorm = []\\nnamesAll = []\\nnames = lola[1:,0]\\nsize = np.shape(lola)\\nfor i in xrange(1,size[1]):\\n    input = lola[1:,i]\\n    ord = np.argsort(input)\\n    inputAll.append(input[ord][:])\\n    namesAll.append(names[ord][:])\\n    inputNorm.append(input)\\n\\n# Save files for matlab\\nf = h5py.File('neurosynth_meta.mat','w')\\nf['inputAll'] = np.asarray(inputAll)\\nf['namesAll'] = namesAll\\nf['names'] = names\\nf['inputNorm'] = inputNorm\\nf.close()\\n\""
       ]
      }
     ],
     "prompt_number": 246
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getOrder(d, thr):\n",
      "    dh = []\n",
      "    for i in d.T:\n",
      "        di = d.T[i]\n",
      "        di[di<=thr] = 0\n",
      "        dh.append(np.average(np.array(xrange(0,len(d.T[i]))) + 1, weights=di))\n",
      "        heatmapOrder = np.argsort(dh)\n",
      "    return heatmapOrder\n",
      "\n",
      "def colorTicks(heatmapOrderVar, figVar):\n",
      "    cl = clusters[heatmapOrderVar]\n",
      "    a = figVar.gca().get_yticklabels()\n",
      "    colorList = [\"green\",\"orange\",\"blue\",\"red\"]\n",
      "    for i in xrange(0,len(a)):\n",
      "        a[i].set_color(colorList[cl[i]]) \n",
      "    return cl,a\n",
      "\n",
      "def leafOrder(inputData):\n",
      "    distanceMatrix = dist.pdist(inputData,  metric='euclidean')\n",
      "    linkageMatrix = hier.linkage(distanceMatrix, method='average', metric='euclidean')\n",
      "    heatmapOrderVar = hier.leaves_list(linkageMatrix)\n",
      "    return heatmapOrderVar\n",
      "\n",
      "def runKmeans(dataVar, numClust):\n",
      "    kmeans = KMeans(n_clusters=numClust, n_init=100, max_iter=100)\n",
      "    dg = dataVar.T/dataVar.T.max().astype(np.float64)\n",
      "    kmeans.fit(dg.T)\n",
      "    clustersVar = kmeans.labels_\n",
      "    return clustersVar\n",
      "    \n",
      "def plotZones(dataVar, axVar, figVar, axTitle):\n",
      "    df = []\n",
      "    df = dataVar.copy()\n",
      "    df.columns = ('medial parietal', 'lateral parietal', 'ventrolateral pfc', \n",
      "                  'medial temporal','ventromedial pfc','dorsolateral pfc','lateral temporal')\n",
      "    df[np.logical_and(df<=thr, df>=(thr*-1))] = 0 \n",
      "    sns.heatmap(df.reindex(df.index[heatmapOrder]), linewidths=1, square=True, center=0, \n",
      "                ax=axVar, vmin=vmin, vmax=vmax)#, vmin=vmin, vmax=vmax)#robust=True, \n",
      "    sns.axlabel(axTitle,'')#, 'NeuroSynth topics terms')  \n",
      "    plt.setp(axVar.get_yticklabels(), visible=False)\n",
      "    \n",
      "    b = figVar.gca().get_xticklabels()\n",
      "    colorlist = [\"red\", \"blue\",\"green\",\"purple\",\"orange\",\"yellow\",\"brown\"]\n",
      "    for i in xrange(0,len(b)): \n",
      "        b[i].set_color(colorlist[i])\n",
      "    cl,a = colorTicks(heatmapOrder, f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 292
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = pd.read_csv('v3-topics-50.txt', sep='\\t', index_col=0)\n",
      "# Remove junk topics and replace with more sensible names. Check the topic-keys file\n",
      "# to see what terms each topic loads on. These topics are identical to those at\n",
      "# http://neurosynth.org/analyses/topics/v3-topics-50/\n",
      "\n",
      "topics_to_keep = [ 4, 6, 14, 17, 18, \n",
      "                   21, 23, 25,# 27, 20,\n",
      "                  29, 30, 31, 33, 35, \n",
      "                  36, 37, 38, 41, 45, \n",
      "                  49, 48] # 43, 16, 22, 46, 44, 1,  \n",
      "labels = [ 'semantics', 'cued attention', 'working memory',  'reading', 'autobiographical memory',\n",
      "           'number', 'inhibition', 'motor',  #'reward', 'visual perception',\n",
      "          'visual attention', 'multisensory perception',  'visuospatial','eye movements', 'action',\n",
      "          'auditory perception', 'language', 'pain', 'long-term memory', 'emotion',  \n",
      "          'social cognition', 'control'] \n",
      "            # 'stress', 'autonomic', 'olfactory', 'learning', 'categorical', 'faces', 'motion', ,\n",
      "features = features.iloc[:, topics_to_keep]\n",
      "features.columns = labels\n",
      "dataset.add_features(features, append=False)\n",
      "\n",
      "# DISTANCE analysis:\n",
      "decoder = decode.Decoder(dataset, method = 'roi')\n",
      "data = decoder.decode([str(('/scr/litauen1/toro/dist_meta/distDMN_MNI_2mm_%s_%s.nii.gz' \n",
      "                            % (str(i * 5), str((i * 5) + 5)))) for i in xrange(0,18)])                    \n",
      "df = []\n",
      "df = data.copy()\n",
      "newnames = []\n",
      "[newnames.append(('%s-%s' % (str(i * 5), str((i*5) + 5)))) for i in xrange(0,len(df.columns))]\n",
      "df.columns = newnames\n",
      "clusters = runKmeans(df,3)\n",
      "\n",
      "# Threshold\n",
      "thr = 3.1\n",
      "vmin = -15\n",
      "vmax = 15\n",
      "heatmapOrder = getOrder(data, thr)\n",
      "df[np.logical_and(df<=thr, df>=(thr*-1))] = 0 \n",
      "    \n",
      "f, (ax1, ax2, ax3) = plt.subplots(nrows=1,ncols=3,figsize=(30, 10), sharey=True)\n",
      "sns.heatmap(df.reindex(df.index[heatmapOrder]), linewidths=1, square=True, center=0, robust=True, \n",
      "            ax=ax1, vmin=vmin, vmax=vmax)\n",
      "sns.axlabel('Distance from DMN peaks (mm)', 'NeuroSynth topics terms')\n",
      "cl,a = colorTicks(heatmapOrder, f)\n",
      "\n",
      "# ZONES analysis:\n",
      "data = decoder.decode([str(('/scr/litauen1/toro/dist_meta/zonesDMN_MNI_2mm_%s.nii.gz' \n",
      "                            % str(i))) for i in range(1,8)])\n",
      "plotZones(data,ax2,f, \"Zones\")\n",
      "\n",
      "# ZONES thr30 analysis:\n",
      "data = decoder.decode([str(('/scr/litauen1/toro/dist_meta/zonesDMNthr30_MNI_2mm_%s.nii.gz' \n",
      "                            % str(i))) for i in range(1,8)])\n",
      "plotZones(data,ax3,f, \"Zones (Thresh<30mm)\")\n",
      "\n",
      "# Save figure\n",
      "f.savefig('Fig_distance_zones_neurosynth.pdf')\n",
      "f.savefig('Fig_distance_zones_neurosynth.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}